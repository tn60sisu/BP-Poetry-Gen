# -*- coding: utf-8 -*-
"""embedding_handler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PiLMytL9S-plS5UaBHRoUvgy2Bx-kL2T
"""

# from google.colab import drive
# drive.mount('/content/drive')
# %cd /content/drive/My Drive/Colab Notebooks/ukp

with open("results/ger1/test.txt", 'r', encoding='utf-8') as f:
  lines = f.readlines()
with open('poems/ger1/test.conll', 'w+', encoding='utf-8') as f:
  for line in lines:
    if '\t' in line:
      f.write(line.split('\t')[0])
      f.write('\n')
    elif ' ' in line:
      f.write(line.split(' ')[0])
      f.write('\n')
    else:
      f.write('\n')

with open('results/ger1/train.txt', 'r', encoding='utf-8') as f:
  txt = []
  for line in f.readlines():
    if '\t' in line:
      temp = line.strip('\n').split('\t')
      txt.append(temp[0] + '\t' + temp[1])
    elif ' ' in line:
      temp = line.strip('\n').split(' ')
      txt.append(temp[0] + '\t' + temp[1])
    else:
      txt.append(line)

with open('poems/ger1/train.txt', 'w+', encoding='utf-8') as f:
  for line in txt:
    f.write(line)
    if '\n' not in line:
      f.write('\n')

with open("results/dev1.tsv", 'r', encoding='utf-8') as f:
  txt = []
  pred = []
  for line in f.readlines():
    if '\t' in line:
      temp = line.strip('\n').split('\t')
      txt.append(temp[0])
      pred.append(temp[1])
    elif ' ' in line:
      temp = line.strip('\n').split(' ')
      txt.append(temp[0])
      pred.append(temp[1])
    else:
      txt.append("")
      pred.append("")

with open('results/ger1/dev.txt', 'r', encoding='utf-8') as f:
  true = []
  for line in f.readlines():
    if '\t' in line:
      temp = line.strip('\n').split('\t')
      true.append(temp[1])
    elif ' ' in line:
      temp = line.strip('\n').split(' ')
      true.append(temp[1])
    else:
      true.append(line)

for t,p,c in zip(txt, pred, true):
  print(t + '\t' + p + '\t' + c)

with open("poems/ger1/dev_result.tsv", 'w+', encoding='utf-8') as f:
  f.write('text\tpredict\tcorrect\n')
  for t,p,c in zip(txt, pred, true):
    line = t + '\t' + p + '\t' + c
    f.write(line)
    if '\n' not in line:
      f.write('\n')

import pandas as pd
df = pd.read_csv("poems/ger1/dev_result.tsv", sep='\t')

with open("results/train.txt", 'r', encoding='utf-8') as f:
  poem = []
  poems = []
  for line in f.readlines():
    if line == '\n':
      continue
    poem.append(line)
    if '. O O' in line:
      poems.append(poem)
      poem = []

from sklearn.model_selection import train_test_split

train, test = train_test_split(poems, test_size = 0.3)
test, dev = train_test_split(test, test_size = 0.33)

with open('results/ger3/dev.txt', 'w+', encoding='utf-8') as f:
  for poem in dev:
    for line in poem:
      f.write(line)
    f.write('\n')

"""#Sentence bert embedding"""

pip install -U sentence-transformers

from sentence_transformers import SentenceTransformer
model = SentenceTransformer('distiluse-base-multilingual-cased')

with open('more_embedding.tsv', 'r', encoding='utf-8') as f:
  text = []
  for line in f.readlines():
    text.append(line.split(' ')[0])

text = [line.replace('_', ' ') for line in text]
text

embeddings = model.encode(text)

with open('sbert_embedding.tsv', 'w+', encoding='utf-8') as f:
  for txt, embed in zip(text, embeddings):
    f.write(txt.replace(' ', '_'))
    for e in embed:
      f.write(' ' + str(e))
    f.write('\n')

with open('sbert_embedding.tsv', 'r', encoding='utf-8') as f:
  lines = f.readlines()

txt = []
labels = []
with open('data/sentiment/dev.txt', 'r', encoding='utf-8') as f:
  for line in f.readlines():
    if '\t' in line:
      parts = line.split('\t')
      txt.append(parts[0])
      labels.append(parts[1])
    elif ' ' in line:
      parts = line.split(' ')
      txt.append(parts[0])
      labels.append(parts[1])
    else:
      txt.append(line)
      labels.append('')

labels2 = [l[2:] if len(l) > 1 else l for l in labels]

inChunk = False
previous = None
iob_labels= []
for label in labels2:
  if len(label) < 2:
    inChunk = False
    iob_labels.append(label)
  else:
    if not inChunk:
      iob_labels.append('B-' + label)
      inChunk = True
    else:
      if previous == label:
        iob_labels.append('I-' + label)
      else:
        iob_labels.append('B-' + label)
  previous = label

with open('results/all/dev.txt', 'w+', encoding='utf-8') as f:
  for t,l in zip(txt, iob_labels):
    if l != '':
      f.write(t + '\t' + l + '\n')
    else:
      f.write(t)